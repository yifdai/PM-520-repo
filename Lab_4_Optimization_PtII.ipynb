{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yifdai/PM-520-repo/blob/main/Lab_4_Optimization_PtII.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ain't no mountain high enough, or: Optimization Pt II\n",
        "Outline for today:\n",
        "1. Gradient Descent Redux\n",
        "2. Newton's Method & Quasi-Newton Methods\n",
        "3. Poisson Regression Lab"
      ],
      "metadata": {
        "id": "D7LCHBjOhm0i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Descent Redux\n",
        "Recall under [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent) we can iteratively optimize a function $f(\\beta)$ by taking steps in the steepest direction,\n",
        "$$ \\hat{\\beta} = \\beta_t - \\rho_t \\nabla f(\\beta_t).$$\n",
        "\n",
        "A helpful way to recast gradient descent is that we seek to perform a series of _local_ optimizations,\n",
        "\n",
        "$$\\hat{\\beta} = \\min_\\beta \\nabla f(\\beta_t)^T \\beta + \\frac{1}{2\\rho_t}\\|\\beta - \\beta_t\\|_2^2.$$\n",
        "\n",
        "To see how these are equivalent let's solve the local problem. but using inner product notation,\n",
        "$$m(\\beta) = \\nabla f(\\beta_t)^T \\beta + \\frac{1}{2\\rho_t} (\\beta - \\beta_t)^T(\\beta - \\beta_t).$$\n",
        "Now, using calculus again,\n",
        "$$\\begin{align*}\n",
        "\\nabla m(\\beta) &= \\nabla [ \\nabla f(\\beta_t)^T \\beta + \\frac{1}{2\\rho_t} (\\beta - \\beta_t)^T(\\beta - \\beta_t)] \\\\\n",
        "&= \\nabla [\\nabla f(\\beta_t)^T \\beta] + \\frac{1}{2\\rho_t} \\nabla [(\\beta - \\beta_t)^T(\\beta - \\beta_t)] \\\\\n",
        "&= \\nabla f(\\beta_t) + \\frac{1}{\\rho_t}(\\beta - \\beta_t) \\Rightarrow \\\\\n",
        "\\hat{\\beta} &= \\beta_t - \\rho_t \\nabla f(\\beta_t).\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "Neat! However, notice that the original local objective can be thought of as minimizing the directional derivative, but with a distance penalty, where that distance is defined by the geometry of the parameter space.\n",
        "\n",
        "$$\\hat{\\beta} = \\min_\\beta \\nabla f(\\beta_t)^T \\beta + \\frac{1}{2\\rho_t}\\text{dist}(\\beta, \\beta_t).$$\n",
        "\n",
        "When the natural geometry is $\\mathbb{R}^p$ then $\\text{dist}(\\cdot) = \\| \\cdot \\|_2^2$, however there are many  geometries that can describe the natural parameter space (for future class ðŸ˜‰)"
      ],
      "metadata": {
        "id": "10ewnuinXmD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Newton's Method for Optimization\n",
        "Can we do better, by considering higher-order information (ie geometry) of\n",
        "the function $f$?\n",
        "\n",
        "Let's consider a 2nd-order [Taylor-series approximation](https://en.wikipedia.org/wiki/Taylor_series) to $f$ around $\\beta_t$ as,\n",
        "\n",
        "$$f(\\beta) \\approx f(\\beta_t) + \\nabla f(\\beta_t)^T (\\beta - \\beta_t) + \\frac{1}{2} (\\beta - \\beta_t)^T H(\\beta_t)(\\beta - \\beta_t),$$ where $H(\\beta_t) = \\nabla^2 f(\\beta_t)$ (i.e. the [Hessian](https://en.wikipedia.org/wiki/Hessian_matrix) of $f$ at $\\beta_t$). If we minimize this _local_ approximation, we see\n",
        "\n",
        "$\\nabla_\\beta f(\\beta) \\approx \\nabla f(\\beta_t) + H(\\beta_t)(\\beta - \\beta_t) = \\nabla f(\\beta_t) + H(\\beta_t)\\beta - H(\\beta_t)\\beta_t â‡’$\n",
        "$$ H(\\beta_t)\\beta = H(\\beta_t)\\beta_t - \\nabla f(\\beta_t).$$\n",
        "\n",
        "We can recognize that this is a [system of linear equations](https://en.wikipedia.org/wiki/System_of_linear_equations) $A x = b$ where $A = H(\\beta_t)$, $x = \\beta$, and $b = H(\\beta_t)\\beta_t - \\nabla f(\\beta_t)$. The solution is given by, $\\hat{x} = A^{-1}b$, which in this case implies,\n",
        "$$ \\hat{\\beta} = H(\\beta_t)^{-1}\\left(H(\\beta_t)\\beta_t - \\nabla f(\\beta_t)\\right) = \\beta_t - H(\\beta_t)^{-1}\\nabla f(\\beta_t).$$\n",
        "\n",
        "\n",
        "\n",
        "[Newton's method](https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization) is only guaranteed to converge _locally_, and can diverge even for _strongly_ [convex functions](https://en.wikipedia.org/wiki/Convex_function) (e.g., $f(\\beta) = \\sqrt{\\beta^2 + 1}$). To address this limitation, we can add a dampening parameter, $\\rho_t$, which gives us our final update form,\n",
        "$$ \\hat{\\beta} = H(\\beta_t)^{-1}(H(\\beta_t)\\beta_t - \\nabla f(\\beta_t)) = \\beta_t - \\rho_t H(\\beta_t)^{-1}\\nabla f(\\beta_t).$$\n",
        "\n",
        "## Quasi-Newton Methods for Optimization\n",
        "What if computing $H(\\beta_t)$ is prohibitive or too costly? Do we need _exact_ second order information to improve on gradient descent's convergence? Given an approximation of $H$, called $B$, i.e. $B(\\beta_t) \\approx H(\\beta_t)$, [_quasi_-Newton methods](https://en.wikipedia.org/wiki/Quasi-Newton_method) optimize for the form\n",
        "$$f(\\beta) \\approx f(\\beta_t) + \\nabla f(\\beta_t)^T (\\beta - \\beta_t) + \\frac{1}{2} (\\beta - \\beta_t)^T B(\\beta_t)(\\beta - \\beta_t),$$ where $B(\\beta_t) \\approx H(\\beta_t)$. Optimizing this statement gives us our update rule,\n",
        "$$ \\hat{\\beta} = \\beta_t - \\rho_t B(\\beta_t)^{-1}\\nabla f(\\beta_t).$$"
      ],
      "metadata": {
        "id": "_b5I2Q37z4_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Poisson Regression\n",
        "\n",
        "$$y_i | x_i \\sim \\text{Poi}(\\lambda_i)$$ where $\\lambda_i := \\exp(x_i^T \\beta)$, and $\\text{Poi}(k | \\lambda) := \\frac{\\lambda^k \\exp(-\\lambda)}{k!}$ is the [PMF](https://en.wikipedia.org/wiki/Probability_mass_function) of the [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution). Given $\\{(y_i, x_i)\\}_{i=1}^n$, we would like to identify the [maximum likelihood parameter estimate](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation) for $\\beta$. In other words, we would to find a value for $\\beta$ such that we maximize the log-likelihood given by,\n",
        "$$\\begin{align*}\n",
        "\\log \\ell(\\beta) &= \\sum_i \\log \\text{Poi}(y_i | \\exp(x_i^T \\beta)) \\\\\n",
        "&= \\sum_i \\log \\left[ \\frac{\\exp(y_i \\cdot x_i^T \\beta) \\exp(-\\exp(x_i^T \\beta))}{y_i!} \\right] \\\\\n",
        "&= \\sum_i \\log \\left[ \\frac{\\exp(y_i \\cdot x_i^T \\beta - \\exp(x_i^T \\beta))}{y_i!} \\right] \\\\\n",
        "&= \\sum_i \\log \\left[\\exp(y_i \\cdot x_i^T \\beta - \\exp(x_i^T \\beta))\\right] - \\log(y_i!) \\\\\n",
        "&= \\sum_i \\left[y_i \\cdot x_i^T \\beta - \\exp(x_i^T \\beta) - \\log(y_i!)\\right] \\\\\n",
        "&= y^T X\\beta - \\exp(X\\beta)^T 1_n - O(1) \\\\\n",
        "&= y^T X\\beta - \\lambda^T 1_n - O(1),\n",
        "\\end{align*}$$\n",
        "where $\\lambda = \\{\\lambda_1, \\dotsc, \\lambda_n\\}.$\n",
        "\n",
        "\n",
        "$$ \\begin{align*}\n",
        "\\nabla_\\beta \\ell &= \\nabla_\\beta \\left[ y^T X\\beta - \\lambda^T 1_n \\right] \\\\\n",
        "&= \\nabla_\\beta [ y^T X\\beta ] - \\nabla_\\beta [\\lambda^T 1_n] \\\\\n",
        "&= \\nabla_\\beta [ y^T X\\beta ] - \\nabla_\\beta [\\exp(X\\beta)^T 1_n] \\\\\n",
        "&= X^T y - X^T \\exp(X\\beta)  \\\\\n",
        "&= X^T y - X^T \\lambda  \\\\\n",
        "&= X^T(y - \\lambda) \\\\\n",
        "\\nabla^2_{\\beta \\beta} \\ell &= \\nabla_{\\beta} X^T(y - \\lambda) \\\\\n",
        "&= \\nabla_{\\beta} \\left[X^T y - X^T \\lambda \\right] \\\\\n",
        "&= - X^T \\nabla_{\\beta}  \\lambda \\\\\n",
        "&= -X^T \\nabla_{\\beta}  \\exp(X\\beta) \\\\\n",
        "&= -X^T \\Lambda X,\n",
        "\\end{align*}$$\n",
        "where $\\Lambda = \\text{diag}(\\lambda)$, i.e. $\\Lambda_{ii} = \\lambda_i$ and $\\Lambda_{ij} = 0$ for $i \\neq j$.\n",
        "\n",
        "To illustrate how $\\nabla_{\\beta}  \\exp(X\\beta) = \\Lambda X$ (i.e. last step in Hessian calculation), recall that the [Jacobian](https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant) of a function $f : \\mathbb{R}^n â†’ \\mathbb{R}^m$ is the $m \\times n$ matrix $J$ such that $J_{ij} = \\frac{âˆ‚f_i}{âˆ‚j}$. In this case we are computing the Jacobian for $\\exp(X\\beta)$, which is $\\mathbb{R}^p â†’ \\mathbb{R}^n$, so our final Jacobian for $\\exp(X\\beta)$ should have shape $n \\times p$. Notice that $J_{i,j} = \\frac{\\partial}{\\partial \\beta_j} \\exp(x_i^T \\beta) = x_{ij}\\exp(x_i^T \\beta)$, thus $J_{i, .} = \\exp(x_i^T \\beta) x_i^T$. Repeating this for each $i$ we have $$âˆ‡_\\beta \\exp(X \\beta) = J(\\exp(X \\beta)) = \\begin{bmatrix} J_{1,.} \\\\ â‹® \\\\ J_{n,.} \\end{bmatrix} =\n",
        "\\begin{bmatrix} \\exp(x_1^T \\beta) x_1^T \\\\ â‹® \\\\ \\exp(x_n^T \\beta) x_n^T \\end{bmatrix}  =\n",
        "\\begin{bmatrix} \\lambda_1 x_1^T \\\\ â‹® \\\\ \\lambda_n x_n^T\\end{bmatrix} = \\Lambda X.$$\n",
        "\n",
        "We can fit using Newton's method. =>\n",
        "$$\\begin{align*}\n",
        "\\beta(t+1) &= \\beta(t) - H(\\beta(t))^{-1}\\nabla \\ell(\\beta_t) \\\\\n",
        "&= \\beta(t) + (X^T \\Lambda(t) X)^{-1} X^T (y - \\lambda) â‡’ \\\\\n",
        "&= (X^T \\Lambda(t) X)^{-1} X^T \\Lambda(t) (\\Lambda(t)^{-1}y + X\\beta(t) - 1)\n",
        "\\end{align*}$$\n",
        "where $\\Lambda(t) := \\text{diag}(\\lambda_1, \\dotsc, \\lambda_n)$."
      ],
      "metadata": {
        "id": "crQSiZATzm9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lineax"
      ],
      "metadata": {
        "id": "NrxzG7-0r2x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as rdm\n",
        "import jax.scipy.stats as stats\n",
        "\n",
        "import lineax as lx\n",
        "\n",
        "@jax.jit\n",
        "def loglikelihood(beta, y, X):\n",
        "  \"\"\"\n",
        "  Our loglikelihood function for $y_i | x_i ~ \\text{Poi}(\\exp(eta_i))$.\n",
        "\n",
        "  beta: beta\n",
        "  y: poisson-distributed observations\n",
        "  X: our design matrix\n",
        "\n",
        "  returns: sum of the logliklihoods of each sample\n",
        "  \"\"\"\n",
        "  eta = X.mv(beta)\n",
        "  return y @ eta - jnp.sum(jnp.exp(eta))\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def irwls_fit(beta, y, X, step_size):\n",
        "  \"\"\"\n",
        "  Perform MLE estimation for $\\beta$ under the model\n",
        "     $y_i | x_i ~ \\text{Poi}(\\exp(x_i^T \\beta))$.\n",
        "\n",
        "  beta: beta\n",
        "  y: poisson-distributed observations\n",
        "  X: our design matrix\n",
        "\n",
        "  returns: updated estimate of $\\beta$\n",
        "  \"\"\"\n",
        "  # compute lambda_i := exp(x_i @ beta)\n",
        "  eta = X.mv(beta)\n",
        "  d_i = jnp.exp(eta)\n",
        "  d_sqrt = jnp.sqrt(d_i)\n",
        "\n",
        "  # compute z_i := Lambda^{1/2}(Lambda^-1 y + X @beta - 1)\n",
        "  z = (y / d_i + eta - 1) * d_sqrt\n",
        "\n",
        "  # X* := Lambda^{1/2} X\n",
        "  # we use linear operators to postpone any computation\n",
        "  X_star = lx.DiagonalLinearOperator(d_sqrt) @ X\n",
        "\n",
        "  # lineax can solve normal equations iteratively as (t(X*) @ (X* @ guess)) - z\n",
        "  solution = lx.linear_solve(X_star, z, solver=lx.NormalCG(atol=1e-4, rtol=1e-3))\n",
        "  beta = solution.value\n",
        "\n",
        "  return beta\n",
        "\n",
        "\n",
        "def poiss_reg(y, X, fit_func, step_size = 1.0, max_iter=100, tol=1e-3):\n",
        "  \"\"\"\n",
        "  Perform MLE estimation for $\\beta$ under the model\n",
        "     $y_i | x_i ~ \\text{Poi}(\\exp(x_i^T \\beta))$.\n",
        "\n",
        "  y: poisson-distributed observations\n",
        "  X: our design matrix\n",
        "  max_iter: the maximum number of iterations to perform optimization\n",
        "  tol:\n",
        "\n",
        "  returns: updated estimate of $\\beta$\n",
        "  \"\"\"\n",
        "  # intialize eta := X @ beta\n",
        "  n, p = X.shape\n",
        "\n",
        "  # fake bookkeeping\n",
        "  loglike = -100000\n",
        "  delta = 10000\n",
        "\n",
        "  # convert to a linear operator for lineax\n",
        "  X = lx.MatrixLinearOperator(X)\n",
        "\n",
        "  # initialize using OLS estimate and normalizing for downstream stability\n",
        "  sol = lx.linear_solve(X, (y - jnp.mean(y))/2, solver=lx.NormalCG(atol=1e-4, rtol=1e-3))\n",
        "  beta = sol.value\n",
        "  beta = beta / jnp.linalg.norm(beta)\n",
        "\n",
        "  for epoch in range(max_iter):\n",
        "\n",
        "    # fit using our function\n",
        "    beta = fit_func(beta, y, X, step_size)\n",
        "\n",
        "    # evaluate log likelihood\n",
        "    newll = loglikelihood(beta, y, X)\n",
        "\n",
        "    # take delta and check if we can stop\n",
        "    delta = jnp.fabs(newll - loglike)\n",
        "    print(f\"Log likelihood[{epoch}] = {newll}\")\n",
        "    if delta < tol:\n",
        "      break\n",
        "\n",
        "    # replace old value\n",
        "    loglike = newll\n",
        "\n",
        "  return beta"
      ],
      "metadata": {
        "id": "DKK1oqZMztkU"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's simulate a poisson regression model with N samples and P variables\n",
        "# we need X (N,P), beta (P,) and y (N,)\n",
        "N = 1000\n",
        "P = 5\n",
        "\n",
        "# initialize PRNG env\n",
        "seed = 0\n",
        "key = rdm.PRNGKey(seed)\n",
        "\n",
        "# TODO: split key for each random call\n",
        "key_x, key_b, key_y = rdm.split(key, num=3)\n",
        "\n",
        "# TODO: compute lambda_i = exp(x_i' \\beta)\n",
        "X = rdm.normal(key_x, shape=(N, P))\n",
        "beta = rdm.normal(key_b, shape=(P, ))\n",
        "eta = X @ beta\n",
        "Lambda = jnp.exp(eta)\n",
        "\n",
        "# TODO: sample y from Poi(lambda_i)\n",
        "y = rdm.poisson(key_y, shape=(N, ), lam=Lambda)\n",
        "# estimate beta using our irwls function\n",
        "# fit_func has signature (eta, y, X, step_size)\n",
        "beta_hat = poiss_reg(y, X, irwls_fit)\n",
        "print(f\"beta = {beta}\")\n",
        "print(f\"hat(beta) = {beta_hat}\")"
      ],
      "metadata": {
        "id": "nRai4qWiz1_R",
        "outputId": "eb6f1067-68bb-41c2-98e7-131b2f199427",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log likelihood[0] = -inf\n",
            "Log likelihood[1] = -1000.0\n",
            "Log likelihood[2] = -inf\n",
            "Log likelihood[3] = -1000.0\n",
            "Log likelihood[4] = -inf\n",
            "Log likelihood[5] = -1000.0\n",
            "Log likelihood[6] = -inf\n",
            "Log likelihood[7] = -1000.0\n",
            "Log likelihood[8] = -inf\n",
            "Log likelihood[9] = -1000.0\n",
            "Log likelihood[10] = -inf\n",
            "Log likelihood[11] = -1000.0\n",
            "Log likelihood[12] = -inf\n",
            "Log likelihood[13] = -1000.0\n",
            "Log likelihood[14] = -inf\n",
            "Log likelihood[15] = -1000.0\n",
            "Log likelihood[16] = -inf\n",
            "Log likelihood[17] = -1000.0\n",
            "Log likelihood[18] = -inf\n",
            "Log likelihood[19] = -1000.0\n",
            "Log likelihood[20] = -inf\n",
            "Log likelihood[21] = -1000.0\n",
            "Log likelihood[22] = -inf\n",
            "Log likelihood[23] = -1000.0\n",
            "Log likelihood[24] = -inf\n",
            "Log likelihood[25] = -1000.0\n",
            "Log likelihood[26] = -inf\n",
            "Log likelihood[27] = -1000.0\n",
            "Log likelihood[28] = -inf\n",
            "Log likelihood[29] = -1000.0\n",
            "Log likelihood[30] = -inf\n",
            "Log likelihood[31] = -1000.0\n",
            "Log likelihood[32] = -inf\n",
            "Log likelihood[33] = -1000.0\n",
            "Log likelihood[34] = -inf\n",
            "Log likelihood[35] = -1000.0\n",
            "Log likelihood[36] = -inf\n",
            "Log likelihood[37] = -1000.0\n",
            "Log likelihood[38] = -inf\n",
            "Log likelihood[39] = -1000.0\n",
            "Log likelihood[40] = -inf\n",
            "Log likelihood[41] = -1000.0\n",
            "Log likelihood[42] = -inf\n",
            "Log likelihood[43] = -1000.0\n",
            "Log likelihood[44] = -inf\n",
            "Log likelihood[45] = -1000.0\n",
            "Log likelihood[46] = -inf\n",
            "Log likelihood[47] = -1000.0\n",
            "Log likelihood[48] = -inf\n",
            "Log likelihood[49] = -1000.0\n",
            "Log likelihood[50] = -inf\n",
            "Log likelihood[51] = -1000.0\n",
            "Log likelihood[52] = -inf\n",
            "Log likelihood[53] = -1000.0\n",
            "Log likelihood[54] = -inf\n",
            "Log likelihood[55] = -1000.0\n",
            "Log likelihood[56] = -inf\n",
            "Log likelihood[57] = -1000.0\n",
            "Log likelihood[58] = -inf\n",
            "Log likelihood[59] = -1000.0\n",
            "Log likelihood[60] = -inf\n",
            "Log likelihood[61] = -1000.0\n",
            "Log likelihood[62] = -inf\n",
            "Log likelihood[63] = -1000.0\n",
            "Log likelihood[64] = -inf\n",
            "Log likelihood[65] = -1000.0\n",
            "Log likelihood[66] = -inf\n",
            "Log likelihood[67] = -1000.0\n",
            "Log likelihood[68] = -inf\n",
            "Log likelihood[69] = -1000.0\n",
            "Log likelihood[70] = -inf\n",
            "Log likelihood[71] = -1000.0\n",
            "Log likelihood[72] = -inf\n",
            "Log likelihood[73] = -1000.0\n",
            "Log likelihood[74] = -inf\n",
            "Log likelihood[75] = -1000.0\n",
            "Log likelihood[76] = -inf\n",
            "Log likelihood[77] = -1000.0\n",
            "Log likelihood[78] = -inf\n",
            "Log likelihood[79] = -1000.0\n",
            "Log likelihood[80] = -inf\n",
            "Log likelihood[81] = -1000.0\n",
            "Log likelihood[82] = -inf\n",
            "Log likelihood[83] = -1000.0\n",
            "Log likelihood[84] = -inf\n",
            "Log likelihood[85] = -1000.0\n",
            "Log likelihood[86] = -inf\n",
            "Log likelihood[87] = -1000.0\n",
            "Log likelihood[88] = -inf\n",
            "Log likelihood[89] = -1000.0\n",
            "Log likelihood[90] = -inf\n",
            "Log likelihood[91] = -1000.0\n",
            "Log likelihood[92] = -inf\n",
            "Log likelihood[93] = -1000.0\n",
            "Log likelihood[94] = -inf\n",
            "Log likelihood[95] = -1000.0\n",
            "Log likelihood[96] = -inf\n",
            "Log likelihood[97] = -1000.0\n",
            "Log likelihood[98] = -inf\n",
            "Log likelihood[99] = -1000.0\n",
            "beta = [-2.4424558  -2.0356805   0.20554423 -0.3535502  -0.76197404]\n",
            "hat(beta) = [0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's implement poisson regression using _only_ gradient information to perform inference\n",
        "# and measure how quickly it converges compared with the Newton method\n",
        "def grad_fit(beta, y, X, step_size):\n",
        "  eta = X.mv(beta)\n",
        "  grad = X.T.mv(y - jnp.exp(eta))\n",
        "  return beta + step_size * grad\n",
        "\n",
        "# NB: we can transpose a lx.MatrixLinearOperator (say X) as X.transpose()\n",
        "# NB: we compute matrix-vector produces using a lx.MatrixLinearOperator as X.mv(v)\n",
        "step_size = 1e-7\n",
        "beta_hat = poiss_reg(y, X, grad_fit, step_size, max_iter=1000)\n",
        "print(f\"beta = {beta}\")\n",
        "print(f\"hat(beta) = {beta_hat}\")"
      ],
      "metadata": {
        "id": "ZalxS2NOOfiV",
        "outputId": "6dd102a4-1ad6-4b71-f03d-7adc5449fe58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log likelihood[0] = 370004.5625\n",
            "Log likelihood[1] = 382793.875\n",
            "Log likelihood[2] = 395572.625\n",
            "Log likelihood[3] = 408339.375\n",
            "Log likelihood[4] = 421092.96875\n",
            "Log likelihood[5] = 433832.84375\n",
            "Log likelihood[6] = 446558.1875\n",
            "Log likelihood[7] = 459266.65625\n",
            "Log likelihood[8] = 471957.78125\n",
            "Log likelihood[9] = 484629.90625\n",
            "Log likelihood[10] = 497281.375\n",
            "Log likelihood[11] = 509910.25\n",
            "Log likelihood[12] = 522514.5625\n",
            "Log likelihood[13] = 535091.875\n",
            "Log likelihood[14] = 547640.9375\n",
            "Log likelihood[15] = 560158.0\n",
            "Log likelihood[16] = 572641.0\n",
            "Log likelihood[17] = 585086.3125\n",
            "Log likelihood[18] = 597490.3125\n",
            "Log likelihood[19] = 609850.75\n",
            "Log likelihood[20] = 622161.4375\n",
            "Log likelihood[21] = 634420.9375\n",
            "Log likelihood[22] = 646622.0\n",
            "Log likelihood[23] = 658760.8125\n",
            "Log likelihood[24] = 670830.1875\n",
            "Log likelihood[25] = 682825.3125\n",
            "Log likelihood[26] = 694740.75\n",
            "Log likelihood[27] = 706566.4375\n",
            "Log likelihood[28] = 718296.25\n",
            "Log likelihood[29] = 729921.9375\n",
            "Log likelihood[30] = 741433.9375\n",
            "Log likelihood[31] = 752822.5\n",
            "Log likelihood[32] = 764077.9375\n",
            "Log likelihood[33] = 775189.25\n",
            "Log likelihood[34] = 786143.8125\n",
            "Log likelihood[35] = 796930.25\n",
            "Log likelihood[36] = 807533.75\n",
            "Log likelihood[37] = 817943.125\n",
            "Log likelihood[38] = 828143.5\n",
            "Log likelihood[39] = 838119.6875\n",
            "Log likelihood[40] = 847857.875\n",
            "Log likelihood[41] = 857342.375\n",
            "Log likelihood[42] = 866558.25\n",
            "Log likelihood[43] = 875491.625\n",
            "Log likelihood[44] = 884126.625\n",
            "Log likelihood[45] = 892450.0625\n",
            "Log likelihood[46] = 900451.4375\n",
            "Log likelihood[47] = 908115.625\n",
            "Log likelihood[48] = 915436.625\n",
            "Log likelihood[49] = 922403.4375\n",
            "Log likelihood[50] = 929011.875\n",
            "Log likelihood[51] = 935258.0\n",
            "Log likelihood[52] = 941140.8125\n",
            "Log likelihood[53] = 946661.3125\n",
            "Log likelihood[54] = 951824.1875\n",
            "Log likelihood[55] = 956636.625\n",
            "Log likelihood[56] = 961107.75\n",
            "Log likelihood[57] = 965250.3125\n",
            "Log likelihood[58] = 969077.125\n",
            "Log likelihood[59] = 972604.125\n",
            "Log likelihood[60] = 975849.625\n",
            "Log likelihood[61] = 978830.3125\n",
            "Log likelihood[62] = 981566.0625\n",
            "Log likelihood[63] = 984075.1875\n",
            "Log likelihood[64] = 986377.0\n",
            "Log likelihood[65] = 988489.625\n",
            "Log likelihood[66] = 990431.875\n",
            "Log likelihood[67] = 992218.375\n",
            "Log likelihood[68] = 993866.0625\n",
            "Log likelihood[69] = 995389.0625\n",
            "Log likelihood[70] = 996800.625\n",
            "Log likelihood[71] = 998113.0\n",
            "Log likelihood[72] = 999336.375\n",
            "Log likelihood[73] = 1000479.125\n",
            "Log likelihood[74] = 1001551.75\n",
            "Log likelihood[75] = 1002559.0\n",
            "Log likelihood[76] = 1003509.75\n",
            "Log likelihood[77] = 1004406.75\n",
            "Log likelihood[78] = 1005257.375\n",
            "Log likelihood[79] = 1006065.375\n",
            "Log likelihood[80] = 1006833.375\n",
            "Log likelihood[81] = 1007564.3125\n",
            "Log likelihood[82] = 1008261.875\n",
            "Log likelihood[83] = 1008928.0\n",
            "Log likelihood[84] = 1009564.9375\n",
            "Log likelihood[85] = 1010173.75\n",
            "Log likelihood[86] = 1010756.0\n",
            "Log likelihood[87] = 1011314.1875\n",
            "Log likelihood[88] = 1011848.125\n",
            "Log likelihood[89] = 1012360.375\n",
            "Log likelihood[90] = 1012851.8125\n",
            "Log likelihood[91] = 1013322.625\n",
            "Log likelihood[92] = 1013773.8125\n",
            "Log likelihood[93] = 1014206.4375\n",
            "Log likelihood[94] = 1014621.4375\n",
            "Log likelihood[95] = 1015018.75\n",
            "Log likelihood[96] = 1015400.75\n",
            "Log likelihood[97] = 1015766.125\n",
            "Log likelihood[98] = 1016116.5\n",
            "Log likelihood[99] = 1016452.0\n",
            "Log likelihood[100] = 1016773.5625\n",
            "Log likelihood[101] = 1017081.625\n",
            "Log likelihood[102] = 1017376.625\n",
            "Log likelihood[103] = 1017659.375\n",
            "Log likelihood[104] = 1017929.375\n",
            "Log likelihood[105] = 1018188.75\n",
            "Log likelihood[106] = 1018436.0625\n",
            "Log likelihood[107] = 1018673.375\n",
            "Log likelihood[108] = 1018899.875\n",
            "Log likelihood[109] = 1019117.4375\n",
            "Log likelihood[110] = 1019324.75\n",
            "Log likelihood[111] = 1019522.125\n",
            "Log likelihood[112] = 1019712.8125\n",
            "Log likelihood[113] = 1019894.0625\n",
            "Log likelihood[114] = 1020067.75\n",
            "Log likelihood[115] = 1020233.0625\n",
            "Log likelihood[116] = 1020391.875\n",
            "Log likelihood[117] = 1020543.375\n",
            "Log likelihood[118] = 1020687.375\n",
            "Log likelihood[119] = 1020825.4375\n",
            "Log likelihood[120] = 1020957.875\n",
            "Log likelihood[121] = 1021083.3125\n",
            "Log likelihood[122] = 1021204.125\n",
            "Log likelihood[123] = 1021318.875\n",
            "Log likelihood[124] = 1021428.75\n",
            "Log likelihood[125] = 1021533.0625\n",
            "Log likelihood[126] = 1021633.625\n",
            "Log likelihood[127] = 1021728.8125\n",
            "Log likelihood[128] = 1021819.625\n",
            "Log likelihood[129] = 1021907.1875\n",
            "Log likelihood[130] = 1021990.25\n",
            "Log likelihood[131] = 1022070.0625\n",
            "Log likelihood[132] = 1022145.5625\n",
            "Log likelihood[133] = 1022218.125\n",
            "Log likelihood[134] = 1022286.875\n",
            "Log likelihood[135] = 1022353.125\n",
            "Log likelihood[136] = 1022416.0\n",
            "Log likelihood[137] = 1022476.25\n",
            "Log likelihood[138] = 1022533.5\n",
            "Log likelihood[139] = 1022588.875\n",
            "Log likelihood[140] = 1022641.375\n",
            "Log likelihood[141] = 1022690.1875\n",
            "Log likelihood[142] = 1022738.125\n",
            "Log likelihood[143] = 1022783.1875\n",
            "Log likelihood[144] = 1022827.5625\n",
            "Log likelihood[145] = 1022869.8125\n",
            "Log likelihood[146] = 1022909.5\n",
            "Log likelihood[147] = 1022947.5\n",
            "Log likelihood[148] = 1022983.875\n",
            "Log likelihood[149] = 1023018.875\n",
            "Log likelihood[150] = 1023052.5\n",
            "Log likelihood[151] = 1023084.5\n",
            "Log likelihood[152] = 1023115.75\n",
            "Log likelihood[153] = 1023144.375\n",
            "Log likelihood[154] = 1023172.25\n",
            "Log likelihood[155] = 1023198.4375\n",
            "Log likelihood[156] = 1023224.125\n",
            "Log likelihood[157] = 1023248.625\n",
            "Log likelihood[158] = 1023272.0\n",
            "Log likelihood[159] = 1023294.0\n",
            "Log likelihood[160] = 1023315.5\n",
            "Log likelihood[161] = 1023336.25\n",
            "Log likelihood[162] = 1023356.6875\n",
            "Log likelihood[163] = 1023374.75\n",
            "Log likelihood[164] = 1023393.4375\n",
            "Log likelihood[165] = 1023410.125\n",
            "Log likelihood[166] = 1023427.0625\n",
            "Log likelihood[167] = 1023443.125\n",
            "Log likelihood[168] = 1023458.625\n",
            "Log likelihood[169] = 1023473.5\n",
            "Log likelihood[170] = 1023488.0\n",
            "Log likelihood[171] = 1023501.375\n",
            "Log likelihood[172] = 1023514.25\n",
            "Log likelihood[173] = 1023526.0\n",
            "Log likelihood[174] = 1023539.0\n",
            "Log likelihood[175] = 1023550.4375\n",
            "Log likelihood[176] = 1023562.125\n",
            "Log likelihood[177] = 1023572.375\n",
            "Log likelihood[178] = 1023582.8125\n",
            "Log likelihood[179] = 1023592.9375\n",
            "Log likelihood[180] = 1023602.0\n",
            "Log likelihood[181] = 1023611.375\n",
            "Log likelihood[182] = 1023620.25\n",
            "Log likelihood[183] = 1023629.0\n",
            "Log likelihood[184] = 1023636.8125\n",
            "Log likelihood[185] = 1023644.75\n",
            "Log likelihood[186] = 1023652.625\n",
            "Log likelihood[187] = 1023660.0\n",
            "Log likelihood[188] = 1023667.375\n",
            "Log likelihood[189] = 1023674.125\n",
            "Log likelihood[190] = 1023680.6875\n",
            "Log likelihood[191] = 1023687.25\n",
            "Log likelihood[192] = 1023693.5\n",
            "Log likelihood[193] = 1023699.375\n",
            "Log likelihood[194] = 1023705.125\n",
            "Log likelihood[195] = 1023710.625\n",
            "Log likelihood[196] = 1023715.875\n",
            "Log likelihood[197] = 1023720.8125\n",
            "Log likelihood[198] = 1023725.5\n",
            "Log likelihood[199] = 1023730.625\n",
            "Log likelihood[200] = 1023734.875\n",
            "Log likelihood[201] = 1023739.625\n",
            "Log likelihood[202] = 1023743.875\n",
            "Log likelihood[203] = 1023748.125\n",
            "Log likelihood[204] = 1023752.625\n",
            "Log likelihood[205] = 1023756.625\n",
            "Log likelihood[206] = 1023760.5\n",
            "Log likelihood[207] = 1023764.375\n",
            "Log likelihood[208] = 1023768.0625\n",
            "Log likelihood[209] = 1023771.75\n",
            "Log likelihood[210] = 1023775.5625\n",
            "Log likelihood[211] = 1023778.375\n",
            "Log likelihood[212] = 1023781.8125\n",
            "Log likelihood[213] = 1023784.5625\n",
            "Log likelihood[214] = 1023787.875\n",
            "Log likelihood[215] = 1023790.625\n",
            "Log likelihood[216] = 1023793.625\n",
            "Log likelihood[217] = 1023796.375\n",
            "Log likelihood[218] = 1023799.25\n",
            "Log likelihood[219] = 1023801.3125\n",
            "Log likelihood[220] = 1023803.875\n",
            "Log likelihood[221] = 1023806.25\n",
            "Log likelihood[222] = 1023808.5\n",
            "Log likelihood[223] = 1023811.0\n",
            "Log likelihood[224] = 1023813.1875\n",
            "Log likelihood[225] = 1023814.875\n",
            "Log likelihood[226] = 1023817.1875\n",
            "Log likelihood[227] = 1023819.1875\n",
            "Log likelihood[228] = 1023821.375\n",
            "Log likelihood[229] = 1023822.9375\n",
            "Log likelihood[230] = 1023824.8125\n",
            "Log likelihood[231] = 1023826.625\n",
            "Log likelihood[232] = 1023828.6875\n",
            "Log likelihood[233] = 1023830.875\n",
            "Log likelihood[234] = 1023832.125\n",
            "Log likelihood[235] = 1023834.0\n",
            "Log likelihood[236] = 1023835.125\n",
            "Log likelihood[237] = 1023837.0625\n",
            "Log likelihood[238] = 1023838.125\n",
            "Log likelihood[239] = 1023840.3125\n",
            "Log likelihood[240] = 1023841.5625\n",
            "Log likelihood[241] = 1023842.6875\n",
            "Log likelihood[242] = 1023844.75\n",
            "Log likelihood[243] = 1023846.125\n",
            "Log likelihood[244] = 1023847.875\n",
            "Log likelihood[245] = 1023849.0\n",
            "Log likelihood[246] = 1023850.5\n",
            "Log likelihood[247] = 1023851.3125\n",
            "Log likelihood[248] = 1023853.0\n",
            "Log likelihood[249] = 1023854.0\n",
            "Log likelihood[250] = 1023855.375\n",
            "Log likelihood[251] = 1023856.25\n",
            "Log likelihood[252] = 1023856.875\n",
            "Log likelihood[253] = 1023857.875\n",
            "Log likelihood[254] = 1023858.875\n",
            "Log likelihood[255] = 1023859.8125\n",
            "Log likelihood[256] = 1023861.1875\n",
            "Log likelihood[257] = 1023862.0\n",
            "Log likelihood[258] = 1023862.875\n",
            "Log likelihood[259] = 1023863.5\n",
            "Log likelihood[260] = 1023864.8125\n",
            "Log likelihood[261] = 1023865.5\n",
            "Log likelihood[262] = 1023866.875\n",
            "Log likelihood[263] = 1023867.5\n",
            "Log likelihood[264] = 1023868.1875\n",
            "Log likelihood[265] = 1023869.3125\n",
            "Log likelihood[266] = 1023870.0625\n",
            "Log likelihood[267] = 1023870.4375\n",
            "Log likelihood[268] = 1023871.0\n",
            "Log likelihood[269] = 1023872.0625\n",
            "Log likelihood[270] = 1023872.625\n",
            "Log likelihood[271] = 1023872.6875\n",
            "Log likelihood[272] = 1023873.9375\n",
            "Log likelihood[273] = 1023874.5\n",
            "Log likelihood[274] = 1023875.1875\n",
            "Log likelihood[275] = 1023875.875\n",
            "Log likelihood[276] = 1023876.5625\n",
            "Log likelihood[277] = 1023876.625\n",
            "Log likelihood[278] = 1023877.8125\n",
            "Log likelihood[279] = 1023878.125\n",
            "Log likelihood[280] = 1023878.75\n",
            "Log likelihood[281] = 1023879.1875\n",
            "Log likelihood[282] = 1023880.0\n",
            "Log likelihood[283] = 1023880.5\n",
            "Log likelihood[284] = 1023880.25\n",
            "Log likelihood[285] = 1023881.125\n",
            "Log likelihood[286] = 1023882.0\n",
            "Log likelihood[287] = 1023882.125\n",
            "Log likelihood[288] = 1023882.8125\n",
            "Log likelihood[289] = 1023883.0\n",
            "Log likelihood[290] = 1023883.75\n",
            "Log likelihood[291] = 1023884.0625\n",
            "Log likelihood[292] = 1023884.625\n",
            "Log likelihood[293] = 1023885.3125\n",
            "Log likelihood[294] = 1023885.4375\n",
            "Log likelihood[295] = 1023886.0\n",
            "Log likelihood[296] = 1023886.5\n",
            "Log likelihood[297] = 1023886.8125\n",
            "Log likelihood[298] = 1023887.0625\n",
            "Log likelihood[299] = 1023887.5625\n",
            "Log likelihood[300] = 1023887.75\n",
            "Log likelihood[301] = 1023888.125\n",
            "Log likelihood[302] = 1023888.1875\n",
            "Log likelihood[303] = 1023888.375\n",
            "Log likelihood[304] = 1023889.0\n",
            "Log likelihood[305] = 1023889.4375\n",
            "Log likelihood[306] = 1023889.8125\n",
            "Log likelihood[307] = 1023889.6875\n",
            "Log likelihood[308] = 1023890.0\n",
            "Log likelihood[309] = 1023890.125\n",
            "Log likelihood[310] = 1023891.0\n",
            "Log likelihood[311] = 1023891.25\n",
            "Log likelihood[312] = 1023891.25\n",
            "beta = [-2.4424558  -2.0356805   0.20554423 -0.3535502  -0.76197404]\n",
            "hat(beta) = [-2.4371722  -2.0295906   0.20570269 -0.36843917 -0.77006805]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automatic differentiation\n",
        "Chain rules, okay! Notes TBD"
      ],
      "metadata": {
        "id": "WbJ1nlWE0R7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's not worry and use autodiff\n",
        "auto_grad_ll = jax.grad(loglikelihood)\n",
        "\n",
        "def jax_grad_step(beta, y, X, step_size):\n",
        "  grad = auto_grad_ll(beta, y, X)\n",
        "  return beta + step_size * grad\n",
        "\n",
        "# NB: we can transpose a lx.MatrixLinearOperator (say X) as X.transpose()\n",
        "# NB: we compute matrix-vector produces using a lx.MatrixLinearOperator as X.mv(v)\n",
        "step_size = 1e-7\n",
        "beta_hat = poiss_reg(y, X, jax_grad_step, step_size, max_iter=1000)\n",
        "print(f\"beta = {beta}\")\n",
        "print(f\"hat(beta) = {beta_hat}\")"
      ],
      "metadata": {
        "id": "dSPl_smqUq9y",
        "outputId": "7260ccdd-4625-492a-ea15-8471747507f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log likelihood[0] = 370004.5625\n",
            "Log likelihood[1] = 382793.875\n",
            "Log likelihood[2] = 395572.625\n",
            "Log likelihood[3] = 408339.375\n",
            "Log likelihood[4] = 421092.96875\n",
            "Log likelihood[5] = 433832.84375\n",
            "Log likelihood[6] = 446558.1875\n",
            "Log likelihood[7] = 459266.65625\n",
            "Log likelihood[8] = 471957.8125\n",
            "Log likelihood[9] = 484629.9375\n",
            "Log likelihood[10] = 497281.375\n",
            "Log likelihood[11] = 509910.25\n",
            "Log likelihood[12] = 522514.5\n",
            "Log likelihood[13] = 535091.9375\n",
            "Log likelihood[14] = 547640.9375\n",
            "Log likelihood[15] = 560158.0\n",
            "Log likelihood[16] = 572641.0\n",
            "Log likelihood[17] = 585086.25\n",
            "Log likelihood[18] = 597490.25\n",
            "Log likelihood[19] = 609850.8125\n",
            "Log likelihood[20] = 622161.4375\n",
            "Log likelihood[21] = 634420.875\n",
            "Log likelihood[22] = 646622.0\n",
            "Log likelihood[23] = 658760.8125\n",
            "Log likelihood[24] = 670830.1875\n",
            "Log likelihood[25] = 682825.3125\n",
            "Log likelihood[26] = 694740.6875\n",
            "Log likelihood[27] = 706566.375\n",
            "Log likelihood[28] = 718296.25\n",
            "Log likelihood[29] = 729921.9375\n",
            "Log likelihood[30] = 741433.9375\n",
            "Log likelihood[31] = 752822.4375\n",
            "Log likelihood[32] = 764077.875\n",
            "Log likelihood[33] = 775189.25\n",
            "Log likelihood[34] = 786143.875\n",
            "Log likelihood[35] = 796930.1875\n",
            "Log likelihood[36] = 807533.75\n",
            "Log likelihood[37] = 817943.125\n",
            "Log likelihood[38] = 828143.5\n",
            "Log likelihood[39] = 838119.625\n",
            "Log likelihood[40] = 847857.8125\n",
            "Log likelihood[41] = 857342.375\n",
            "Log likelihood[42] = 866558.25\n",
            "Log likelihood[43] = 875491.6875\n",
            "Log likelihood[44] = 884126.6875\n",
            "Log likelihood[45] = 892450.125\n",
            "Log likelihood[46] = 900451.5\n",
            "Log likelihood[47] = 908115.625\n",
            "Log likelihood[48] = 915436.6875\n",
            "Log likelihood[49] = 922403.4375\n",
            "Log likelihood[50] = 929011.9375\n",
            "Log likelihood[51] = 935258.0\n",
            "Log likelihood[52] = 941140.8125\n",
            "Log likelihood[53] = 946661.375\n",
            "Log likelihood[54] = 951824.25\n",
            "Log likelihood[55] = 956636.5625\n",
            "Log likelihood[56] = 961107.75\n",
            "Log likelihood[57] = 965250.375\n",
            "Log likelihood[58] = 969077.1875\n",
            "Log likelihood[59] = 972604.0625\n",
            "Log likelihood[60] = 975849.6875\n",
            "Log likelihood[61] = 978830.1875\n",
            "Log likelihood[62] = 981566.0625\n",
            "Log likelihood[63] = 984075.125\n",
            "Log likelihood[64] = 986377.0625\n",
            "Log likelihood[65] = 988489.5625\n",
            "Log likelihood[66] = 990432.0\n",
            "Log likelihood[67] = 992218.375\n",
            "Log likelihood[68] = 993866.1875\n",
            "Log likelihood[69] = 995389.1875\n",
            "Log likelihood[70] = 996800.875\n",
            "Log likelihood[71] = 998113.125\n",
            "Log likelihood[72] = 999336.4375\n",
            "Log likelihood[73] = 1000479.125\n",
            "Log likelihood[74] = 1001551.875\n",
            "Log likelihood[75] = 1002559.0\n",
            "Log likelihood[76] = 1003509.75\n",
            "Log likelihood[77] = 1004406.875\n",
            "Log likelihood[78] = 1005257.375\n",
            "Log likelihood[79] = 1006065.4375\n",
            "Log likelihood[80] = 1006833.375\n",
            "Log likelihood[81] = 1007564.25\n",
            "Log likelihood[82] = 1008261.875\n",
            "Log likelihood[83] = 1008928.125\n",
            "Log likelihood[84] = 1009564.9375\n",
            "Log likelihood[85] = 1010173.625\n",
            "Log likelihood[86] = 1010755.9375\n",
            "Log likelihood[87] = 1011314.125\n",
            "Log likelihood[88] = 1011848.125\n",
            "Log likelihood[89] = 1012360.3125\n",
            "Log likelihood[90] = 1012851.875\n",
            "Log likelihood[91] = 1013322.625\n",
            "Log likelihood[92] = 1013773.8125\n",
            "Log likelihood[93] = 1014206.5\n",
            "Log likelihood[94] = 1014621.375\n",
            "Log likelihood[95] = 1015018.6875\n",
            "Log likelihood[96] = 1015400.75\n",
            "Log likelihood[97] = 1015766.1875\n",
            "Log likelihood[98] = 1016116.5\n",
            "Log likelihood[99] = 1016452.0\n",
            "Log likelihood[100] = 1016773.5625\n",
            "Log likelihood[101] = 1017081.625\n",
            "Log likelihood[102] = 1017376.625\n",
            "Log likelihood[103] = 1017659.375\n",
            "Log likelihood[104] = 1017929.4375\n",
            "Log likelihood[105] = 1018188.625\n",
            "Log likelihood[106] = 1018436.0625\n",
            "Log likelihood[107] = 1018673.375\n",
            "Log likelihood[108] = 1018900.0\n",
            "Log likelihood[109] = 1019117.4375\n",
            "Log likelihood[110] = 1019324.75\n",
            "Log likelihood[111] = 1019522.125\n",
            "Log likelihood[112] = 1019712.75\n",
            "Log likelihood[113] = 1019894.125\n",
            "Log likelihood[114] = 1020067.6875\n",
            "Log likelihood[115] = 1020233.0\n",
            "Log likelihood[116] = 1020391.875\n",
            "Log likelihood[117] = 1020543.3125\n",
            "Log likelihood[118] = 1020687.3125\n",
            "Log likelihood[119] = 1020825.375\n",
            "Log likelihood[120] = 1020957.75\n",
            "Log likelihood[121] = 1021083.375\n",
            "Log likelihood[122] = 1021204.125\n",
            "Log likelihood[123] = 1021318.875\n",
            "Log likelihood[124] = 1021428.75\n",
            "Log likelihood[125] = 1021533.125\n",
            "Log likelihood[126] = 1021633.625\n",
            "Log likelihood[127] = 1021728.8125\n",
            "Log likelihood[128] = 1021819.5625\n",
            "Log likelihood[129] = 1021907.25\n",
            "Log likelihood[130] = 1021990.25\n",
            "Log likelihood[131] = 1022070.0\n",
            "Log likelihood[132] = 1022145.625\n",
            "Log likelihood[133] = 1022218.1875\n",
            "Log likelihood[134] = 1022286.875\n",
            "Log likelihood[135] = 1022353.125\n",
            "Log likelihood[136] = 1022416.0\n",
            "Log likelihood[137] = 1022476.3125\n",
            "Log likelihood[138] = 1022533.4375\n",
            "Log likelihood[139] = 1022589.0625\n",
            "Log likelihood[140] = 1022641.375\n",
            "Log likelihood[141] = 1022690.125\n",
            "Log likelihood[142] = 1022738.0625\n",
            "Log likelihood[143] = 1022783.3125\n",
            "Log likelihood[144] = 1022827.5\n",
            "Log likelihood[145] = 1022869.75\n",
            "Log likelihood[146] = 1022909.5\n",
            "Log likelihood[147] = 1022947.375\n",
            "Log likelihood[148] = 1022983.9375\n",
            "Log likelihood[149] = 1023019.0\n",
            "Log likelihood[150] = 1023052.5\n",
            "Log likelihood[151] = 1023084.375\n",
            "Log likelihood[152] = 1023115.75\n",
            "Log likelihood[153] = 1023144.375\n",
            "Log likelihood[154] = 1023172.125\n",
            "Log likelihood[155] = 1023198.5\n",
            "Log likelihood[156] = 1023224.125\n",
            "Log likelihood[157] = 1023248.6875\n",
            "Log likelihood[158] = 1023272.0\n",
            "Log likelihood[159] = 1023294.0\n",
            "Log likelihood[160] = 1023315.375\n",
            "Log likelihood[161] = 1023336.25\n",
            "Log likelihood[162] = 1023356.6875\n",
            "Log likelihood[163] = 1023374.625\n",
            "Log likelihood[164] = 1023393.375\n",
            "Log likelihood[165] = 1023410.125\n",
            "Log likelihood[166] = 1023427.0\n",
            "Log likelihood[167] = 1023443.125\n",
            "Log likelihood[168] = 1023458.5\n",
            "Log likelihood[169] = 1023473.625\n",
            "Log likelihood[170] = 1023488.125\n",
            "Log likelihood[171] = 1023501.4375\n",
            "Log likelihood[172] = 1023514.25\n",
            "Log likelihood[173] = 1023526.0625\n",
            "Log likelihood[174] = 1023538.875\n",
            "Log likelihood[175] = 1023550.25\n",
            "Log likelihood[176] = 1023562.125\n",
            "Log likelihood[177] = 1023572.3125\n",
            "Log likelihood[178] = 1023582.75\n",
            "Log likelihood[179] = 1023592.9375\n",
            "Log likelihood[180] = 1023602.0\n",
            "Log likelihood[181] = 1023611.375\n",
            "Log likelihood[182] = 1023620.25\n",
            "Log likelihood[183] = 1023628.875\n",
            "Log likelihood[184] = 1023636.875\n",
            "Log likelihood[185] = 1023644.875\n",
            "Log likelihood[186] = 1023652.625\n",
            "Log likelihood[187] = 1023660.0\n",
            "Log likelihood[188] = 1023667.3125\n",
            "Log likelihood[189] = 1023674.125\n",
            "Log likelihood[190] = 1023680.8125\n",
            "Log likelihood[191] = 1023687.3125\n",
            "Log likelihood[192] = 1023693.5625\n",
            "Log likelihood[193] = 1023699.375\n",
            "Log likelihood[194] = 1023705.0\n",
            "Log likelihood[195] = 1023710.625\n",
            "Log likelihood[196] = 1023715.75\n",
            "Log likelihood[197] = 1023720.75\n",
            "Log likelihood[198] = 1023725.5\n",
            "Log likelihood[199] = 1023730.5625\n",
            "Log likelihood[200] = 1023734.875\n",
            "Log likelihood[201] = 1023739.625\n",
            "Log likelihood[202] = 1023743.875\n",
            "Log likelihood[203] = 1023748.125\n",
            "Log likelihood[204] = 1023752.5625\n",
            "Log likelihood[205] = 1023756.625\n",
            "Log likelihood[206] = 1023760.625\n",
            "Log likelihood[207] = 1023764.375\n",
            "Log likelihood[208] = 1023768.125\n",
            "Log likelihood[209] = 1023771.75\n",
            "Log likelihood[210] = 1023775.5\n",
            "Log likelihood[211] = 1023778.375\n",
            "Log likelihood[212] = 1023781.8125\n",
            "Log likelihood[213] = 1023784.625\n",
            "Log likelihood[214] = 1023787.8125\n",
            "Log likelihood[215] = 1023790.5625\n",
            "Log likelihood[216] = 1023793.625\n",
            "Log likelihood[217] = 1023796.4375\n",
            "Log likelihood[218] = 1023799.1875\n",
            "Log likelihood[219] = 1023801.25\n",
            "Log likelihood[220] = 1023803.8125\n",
            "Log likelihood[221] = 1023806.375\n",
            "Log likelihood[222] = 1023808.5\n",
            "Log likelihood[223] = 1023811.0\n",
            "Log likelihood[224] = 1023813.0\n",
            "Log likelihood[225] = 1023814.9375\n",
            "Log likelihood[226] = 1023817.25\n",
            "Log likelihood[227] = 1023819.1875\n",
            "Log likelihood[228] = 1023821.375\n",
            "Log likelihood[229] = 1023822.9375\n",
            "Log likelihood[230] = 1023824.875\n",
            "Log likelihood[231] = 1023826.625\n",
            "Log likelihood[232] = 1023828.75\n",
            "Log likelihood[233] = 1023830.875\n",
            "Log likelihood[234] = 1023832.125\n",
            "Log likelihood[235] = 1023834.0\n",
            "Log likelihood[236] = 1023835.125\n",
            "Log likelihood[237] = 1023837.0\n",
            "Log likelihood[238] = 1023838.1875\n",
            "Log likelihood[239] = 1023840.375\n",
            "Log likelihood[240] = 1023841.375\n",
            "Log likelihood[241] = 1023842.75\n",
            "Log likelihood[242] = 1023844.625\n",
            "Log likelihood[243] = 1023846.125\n",
            "Log likelihood[244] = 1023847.875\n",
            "Log likelihood[245] = 1023849.125\n",
            "Log likelihood[246] = 1023850.375\n",
            "Log likelihood[247] = 1023851.3125\n",
            "Log likelihood[248] = 1023852.875\n",
            "Log likelihood[249] = 1023854.0\n",
            "Log likelihood[250] = 1023855.375\n",
            "Log likelihood[251] = 1023856.25\n",
            "Log likelihood[252] = 1023856.875\n",
            "Log likelihood[253] = 1023857.875\n",
            "Log likelihood[254] = 1023858.875\n",
            "Log likelihood[255] = 1023859.8125\n",
            "Log likelihood[256] = 1023861.1875\n",
            "Log likelihood[257] = 1023862.0\n",
            "Log likelihood[258] = 1023862.9375\n",
            "Log likelihood[259] = 1023863.5\n",
            "Log likelihood[260] = 1023864.8125\n",
            "Log likelihood[261] = 1023865.5\n",
            "Log likelihood[262] = 1023866.875\n",
            "Log likelihood[263] = 1023867.5\n",
            "Log likelihood[264] = 1023868.25\n",
            "Log likelihood[265] = 1023869.4375\n",
            "Log likelihood[266] = 1023870.0625\n",
            "Log likelihood[267] = 1023870.4375\n",
            "Log likelihood[268] = 1023871.0\n",
            "Log likelihood[269] = 1023872.0625\n",
            "Log likelihood[270] = 1023872.625\n",
            "Log likelihood[271] = 1023872.6875\n",
            "Log likelihood[272] = 1023873.9375\n",
            "Log likelihood[273] = 1023874.5\n",
            "Log likelihood[274] = 1023875.1875\n",
            "Log likelihood[275] = 1023875.875\n",
            "Log likelihood[276] = 1023876.625\n",
            "Log likelihood[277] = 1023876.625\n",
            "beta = [-2.4424558  -2.0356805   0.20554423 -0.3535502  -0.76197404]\n",
            "hat(beta) = [-2.435044   -2.0282288   0.20542727 -0.37367764 -0.7739267 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.scipy.linalg as spla\n",
        "\n",
        "# Great! But can we use 2nd order information?\n",
        "auto_hess_ll = jax.hessian(loglikelihood)\n",
        "def jax_newton_step(beta, y, X, step_size):\n",
        "\n",
        "  pass\n",
        "\n",
        "# NB: we can transpose a lx.MatrixLinearOperator (say X) as X.transpose()\n",
        "# NB: we compute matrix-vector produces using a lx.MatrixLinearOperator as X.mv(v)\n",
        "step_size = 1.\n",
        "beta_hat = poiss_reg(y, X, jax_newton_step, step_size, max_iter=1000)\n",
        "print(f\"beta = {beta}\")\n",
        "print(f\"hat(beta) = {beta_hat}\")"
      ],
      "metadata": {
        "id": "qtbqZkAlWPuv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}